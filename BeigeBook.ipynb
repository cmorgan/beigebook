{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Garnering sentiment from the Beige Book"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#Sentiment from unstructured data\n",
      "## (Can robots read Bernanke?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# What is sentiment analysis?\n",
      "\n",
      "* Use of natural language processing and computational linguistics to identifiy and extract subjective information in source materials.\n",
      "\n",
      "* Sentiment analysis aims to determine the attitude of the source author with respect to a topic or the contextual polarity of the document.\n",
      "\n",
      "This is distinct from Sentiment Indicators such as the Commitment of Traders report published by US Commodities Futures Trading Commission."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Why?\n",
      "\n",
      "* Capture intent of market participents\n",
      "* Add extra layer of richness to input signals\n",
      "* Uncorrelated with existing trading signals[1]\n",
      "\n",
      "[1] http://strata.oreilly.com/2011/05/sentiment-analysis-finance.html"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "# Limitations\n",
      "\n",
      "* Humans don't agree on sentiment 85% of the time\\*, machine based sentiment analysis only useful in clear cut situations.\n",
      "* Dangerous to have fully algorithmic trades - example below...\n",
      "\n",
      "\n",
      "\\* Mark Thompson, CEO Lexalytics http://www.lexalytics.com/"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Commercial products\n",
      "\n",
      "* http://www.lexalytics.com/\n",
      "* Bloombergs sentiment index\n",
      "* Twitter index\n",
      "* https://www.marketpsych.com: spin off company from now closed MarketPsych Captial fund http://www.richard.peterson.net/ MD\n",
      "28 percent return from Sept. 2, 2008, through Dec. 31, 2010. The S&P 500 lost 1.6 percent over \n",
      "the same period. \n",
      "\n",
      "* Twitter hedge fund http://www.youtube.com/watch?v=ALILxiBmsAQ#t=96\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Twitter hedge fund: Cayman Atlantic\n",
      "\n",
      "Inspired by this paper:\n",
      "\n",
      "![](files/images/twitter_predicts.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "* measure 6 different moods with lexicon\n",
      "* data of moods fed into algo to give index\n",
      "* they at change in sentiment standard deviation or more, signals global change in equity\n",
      "* 7 langauges monitored\n",
      "* pick diverse basket of intstruments\n",
      "* Picking entire Twittersphere not just CEOs looking for sentiment\n",
      "\n",
      "http://venturebeat.com/2012/05/28/twitter-fueled-hedge-fund-bit-the-dust-but-it-actually-worked/\n",
      "\n",
      "twitter:\n",
      "http://www.sciencedaily.com/releases/2013/10/131007151731.htm\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "notes"
      }
     },
     "source": [
      "Twitter hedge fund notes\n",
      "\n",
      "* Started by Paul Hawtin\n",
      "* Dow Jones was lagging Twitter sentiment by 3 days\n",
      "* Launched Derwent Absoulte Return fund 1st July 2012, closed 1 month after.\n",
      "* Opened Cayman Atlantic in May 2013 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Twitter hedge fund: Cayman Atlantic\n",
      "\n",
      "* http://www.caymanatlantic.com/\n",
      "\n",
      "![Cayman Atlantic performance](files/images/cayman_atlantic.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Other evidence of market use\n",
      "\n",
      "## Tweet retreat \n",
      "\n",
      "* Hacked AP Twitter account\n",
      "\n",
      "![](files/images/ap_twitter.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "* 1% decline in S&P 500\n",
      "\n",
      "![](files/images/tweet_retreat.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Sentiment from the Beige Book?\n",
      "\n",
      "The Beige Book, more formally known as the Summary of Commentary on Current Economic Conditions, is a report published by the United States Federal Reserve Board eight times a year. The report is published in advance of meetings of the Federal Open Market Committee (FOMC), giving an indication of topics of interest. Each report is a gathering of \"anecdotal information on current economic conditions\" by each Federal Reserve Bank in its district from \"Bank and Branch directors and interviews with key business contacts, economists, market experts, and others.\" \n",
      "\n",
      "The Beige Book began its ascent to its status as an economic indicator in 1985 when former Dow Jones reporter Paul Cox requested to see the report. The request was granted forcing competing journalists to demand access to it the following month.\n",
      "\n",
      "###Importance\n",
      "\n",
      "* The Fed uses this report, along with other indicators, to determine interest rate policy at FOMC meetings.\n",
      "* If the Beige Book portrays inflationary pressure then the Fed may raise interest rates.\n",
      "* If the Beige Book portrays recessionary conditions the Fed may lower interest rates.\n",
      "\n",
      "###Availability and history\n",
      "\n",
      "* The Beige Book is released at 2:00pm the Wednesday begore each FOMC meeting, which is held 8 times a year.\n",
      "* Beige Books are available online http://www.minneapolisfed.org/bb/ from **1970**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import beigebook as bb\n",
      "from pandas.tools.plotting import bootstrap_plot\n",
      "import matplotlib as mpl"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load data\n",
      "df = bb.get_df()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# make all fonts bigger, etc\n",
      "font_size = 35\n",
      "fig_size=(30, 20)\n",
      "#mpl.rcParams['axes.titlesize'] = 'xx-large'\n",
      "#mpl.rcParams['axes.labelsize'] = 'xx-large'\n",
      "#mpl.rcParams['xtick.labelsize'] = 'x-large'\n",
      "#mpl.rcParams['ytick.labelsize'] = 'x-large'\n",
      "#mpl.rcParams['legend.fancybox'] = True\n",
      "#mpl.rcParams['legend.fontsize'] = 'large'\n",
      "#mpl.rcParams['font.size'] = 12\n",
      "#mpl.rcParams['axes.linewidth'] = .5\n",
      "#mpl.rcParams['lines.linewidth'] = .5\n",
      "#mpl.rcParams['patch.linewidth'] = .5\n",
      "mpl.rcParams['font.size'] = font_size\n",
      "mpl.rcParams['axes.labelsize'] = font_size / 1.2\n",
      "mpl.rcParams['axes.linewidth'] = font_size / 20.\n",
      "mpl.rcParams['lines.linewidth'] = font_size / 5.\n",
      "mpl.rcParams['axes.titlesize'] = font_size\n",
      "mpl.rcParams['legend.fontsize'] = font_size / 1.2\n",
      "mpl.rcParams['xtick.labelsize'] = font_size / 1.2\n",
      "mpl.rcParams['ytick.labelsize'] = font_size / 1.2\n",
      "mpl.rcParams['figure.figsize'] = fig_size\n",
      "#mpl.rcParams['patch.linewidth'] = 10\n",
      "\n",
      "#mpl.rcParams['axes.color_cycle'] = ['348ABD', '7A68A6', 'A60628', '467821', 'CF4457', '188487', 'E24A33']"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title = 'Number of words in the Beige Book over time'\n",
      "ax = df['number_of_words'].plot(title=title)\n",
      "ylabel = ax.set_ylabel('Number of words')\n",
      "xlabel = ax.set_xlabel('Time')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = bootstrap_plot(df['number_of_words'], size=1, samples=1000)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas.tools.plotting import lag_plot\n",
      "lag = lag_plot(df)\n",
      "print(type(lag))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The lag plot shown has two outliers. Perhpas there were significant economic events which caused these to be longer than usual? "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.sort('number_of_words')[-2:]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "In [1] it is shown asserted that:\n",
      "\n",
      "* media references versus stock trading volume\n",
      "* media references versus market capitalization\n",
      "* **media polarity versus stock returns**\n",
      "* **media subjectivity versus stock trading volume**\n",
      "\n",
      "The formulas for ``Polarity`` and ``Subjectivity`` are as follows:\n",
      "\n",
      "\\begin{align} Polarity = \\frac{N_{pos}-N_{neg}}{N_{pos}+N_{neg}} \\end{align}\n",
      "\n",
      "\n",
      "\\begin{align} Subjectivity= \\frac{N_{pos}+N_{neg}}{N} \\end{align}\n",
      "\n",
      "We investigate two different dictionaries for determining sentiment:\n",
      "\n",
      "1. Harvard IV-4\n",
      "2. Loughran and McDonald Financial Sentiment\n",
      "\n",
      "### Harvard IV-4\n",
      "\n",
      "Dictionary was developed by Harvard for a research tool called ``Inquirer``.\n",
      "http://www.wjh.harvard.edu/~inquirer/homecat.htm\n",
      "\n",
      "### Lougran and McDonald Financial Sentiment\n",
      "\n",
      "Developed by Lougran and McDonald at University of Notre Dame. This differs to the above dictionary as it does not misclassify finance related words as negative - e.g. \"tax, cost, board, foreign, vice, and liability\", simply describe company operation. This dictionary is tuned to 10-K file date returns, post-file date returns, return volatility, allegations of accounting fraud, and company material weakness disclosures.\n",
      "\n",
      "### How do the dictionaries compare?\n",
      "\n",
      "* plot of sentiment vs monthly tbill rate\n",
      "* plot of sentiment vs CPI\n",
      "\n",
      "(plots should show the sentiment in colored bar, and the other data separatley)\n",
      "\n",
      "### How do we evaluate success?\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dreload(bb)\n",
      "bbs = bb.all_bb()\n",
      "df = bb.construct_df(bbs)\n",
      "df.describe()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[['HIV4_Subjectivity', 'LM_Subjectivity']].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[['HIV4_Polarity', 'LM_Polarity']].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "plt.plot_date(x=df.index, y=range(len(df.index)))\n",
      "fig = plt.gcf()\n",
      "fig.set_size_inches(18.5,10.5)\n",
      "#plt.savefig('test2png.png',dpi=100)\n",
      "#fig.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.cm as cm\n",
      "\n",
      "# Create fake data\n",
      "X = df.index\n",
      "Y=list(range(len(df.index)))\n",
      "\n",
      "# Pick a cmap\n",
      "cmap = cm.get_cmap('jet')\n",
      "\n",
      "ax = plt.subplot(111)\n",
      "ax.xaxis_date()\n",
      "\n",
      "for x0,x1 in zip(Y,Y[1:]):\n",
      "    c = cmap((x0-min(Y))/max(Y))\n",
      "    ax.bar([x0,],1.0,x1-x0,\n",
      "            color=c,\n",
      "            linewidth=0)\n",
      "plt.xlim(min(Y),max(Y))\n",
      "#.show()\n",
      "ax.xaxis_date()\n",
      "plt.show(ax)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create fake data\n",
      "X = df.index\n",
      "Y =df['HIV4_Polarity']\n",
      "\n",
      "# Pick a cmap\n",
      "cmap = cm.get_cmap('jet')\n",
      "\n",
      "for x0,x1 in zip(Y,Y[1:]):\n",
      "    c = cmap((x0-Y.min())/Y.max())\n",
      "    plt.bar([x0,],1.0,x1-x0,\n",
      "            color=c,\n",
      "            linewidth=0)\n",
      "plt.xlim(Y.min(),Y.max())\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "reds = plt.get_cmap(\"Reds\")\n",
      "x = np.linspace(0, 10, 10)\n",
      "y = np.log(x)\n",
      "\n",
      "# color by value given a cmap\n",
      "plt.subplot(121)\n",
      "plt.scatter(x, y, c=x, s=100, cmap=reds)\n",
      "\n",
      "\n",
      "# color by value, and add a legend for each\n",
      "plt.subplot(122)\n",
      "norm = plt.normalize()\n",
      "norm.autoscale(x)\n",
      "for i, (x_val, y_val) in enumerate(zip(x, y)):\n",
      "    plt.plot(x_val, y_val, 'o', markersize=10, \n",
      "             color=reds(norm(x_val)),\n",
      "             label='Point %s' % i\n",
      "             )\n",
      "plt.legend(numpoints=1, loc='lower right')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime\n",
      "\n",
      "x = [datetime.datetime(2010, 12, 1, 10, 0),\n",
      "    datetime.datetime(2011, 1, 4, 9, 0),\n",
      "    datetime.datetime(2011, 5, 5, 9, 0)]\n",
      "y = [4, 9, 2]\n",
      "\n",
      "ax = plt.subplot(111)\n",
      "ax.bar(x, y, width=10)\n",
      "ax.xaxis_date()\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tbill = bb.get_tbill()\n",
      "tbill['3 month T-Bill'].dropna().plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tbill = bb.get_tbill2()\n",
      "fig = plt.figure()\n",
      "ax = plt.subplot(111)\n",
      "plt.plot(tbill.index, tbill,label='3 Month Treasury Bill', linewidth=4, color='red')\n",
      "#plt.plot(xdates, e98,'o-',label='E98')\n",
      "#plt.plot(xdates, dies,'o-',label='Diesel')\n",
      "plt.legend(loc=2)\n",
      "plt.xlabel('Year')\n",
      "plt.ylabel('Discount rate')\n",
      " \n",
      "#plates, number = np.loadtxt('newplates.txt',skiprows=1,unpack=True)\n",
      "#xdates2 = [datetime.datetime.strptime(str(int(date)),'%Y') for date in plates]\n",
      " \n",
      "ax2 = ax.twinx()\n",
      "plt.bar(df.index, df['LM_Polarity'],width=25,alpha=0.4,label='Sentiment Polarity (LM)')\n",
      "#plt.ylim(550000,700000)\n",
      "plt.legend(loc=1)\n",
      "plt.ylabel('Polarity')\n",
      "plt.xlabel('Year')\n",
      "plt.grid()\n",
      "fig.set_size_inches(18.5,10.5)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = df.index\n",
      "Y =df['HIV4_Polarity']\n",
      "\n",
      "# Pick a cmap\n",
      "cmap = cm.get_cmap('jet')\n",
      "\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = plt.subplot(111)\n",
      "\n",
      "for x0,x1 in zip(Y,Y[1:]):\n",
      "    c = cmap((x0-Y.min())/Y.max())\n",
      "    plt.bar([x0,],10.0,x1-x0,\n",
      "            color=c,\n",
      "            linewidth=0)\n",
      "\n",
      "\n",
      "#plt.plot(df.index, df['HIV4_Polarity'],'o-',label='E95')\n",
      "#plt.plot(xdates, e98,'o-',label='E98')\n",
      "#plt.plot(xdates, dies,'o-',label='Diesel')\n",
      "plt.legend(loc=2)\n",
      "plt.xlabel('Year')\n",
      "plt.ylabel('Fuel Price (Euro/Litre)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "References:\n",
      "\n",
      "[1] W. Zhang and S. Skiena,  Trading Strategies to Exploit Blog and News Sentiment. ;In Proceedings of ICWSM. 2010. http://www.cs.sunysb.edu/~skiena/lydia/blogtrading.pdf\n",
      "\n",
      "[2] https://www3.nd.edu/~mcdonald/Word_Lists.html\n",
      "\n",
      "Notes:\n",
      "Steve Skiena has a company providing real time sentiment rankings from news and blogs: http://www.cs.sunysb.edu/~skiena/lydia/\n",
      "http://www.stern.nyu.edu/cons/groups/content/documents/webasset/con_038156.pdf\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}